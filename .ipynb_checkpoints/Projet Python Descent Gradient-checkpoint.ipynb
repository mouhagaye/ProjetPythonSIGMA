{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b46a75a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import random\n",
    "\n",
    "\n",
    "# class GradientDescent():\n",
    "    \n",
    "#     \"\"\"Descent gradient class with regularize technique\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     regularize : bool\n",
    "#         If True, the regularization is used.\n",
    "#     bias : bool\n",
    "#         If the True, a bias is added to the features.\n",
    "#     alpha : float > 0\n",
    "#         Coefficient for the step when updating the parameters.\n",
    "    \n",
    "#     Notes\n",
    "#     -----\n",
    "#     This class aims at computing the parameters of a linear model using\n",
    "#     a descent gradient method with or without regularization.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def __init__(self, regularize=False, bias=True, alpha=3e-9, iterations=30000):\n",
    "#         self.bias = bias\n",
    "#         if alpha < 0:\n",
    "#             raise ValueError('Alpha parameter must be > 0. Here {}.'.format(alpha))\n",
    "#         self.alpha = alpha\n",
    "#         self.iterations = iterations\n",
    "#         self.regularize = regularize\n",
    "        \n",
    "#         #set the epsilon value depending on the regularize case\n",
    "#         if regularize:\n",
    "#             self.epsilon = 1e-10\n",
    "#         else:\n",
    "#             self.epsilon = 1e-8\n",
    "    \n",
    "#     def predict(self, new_features):\n",
    "#         \"\"\"Make predictions using the result of the gradient descent\n",
    "        \n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         new_features : 2d sequence of float\n",
    "#             The feature for which to predict the labels.\n",
    "            \n",
    "#         Returns\n",
    "#         -------\n",
    "#         predicted_labels : 2d sequence of float\n",
    "#             The predicted labels\n",
    "        \n",
    "#         Notes\n",
    "#         -----\n",
    "#         The method fit must be called first.\n",
    "#         \"\"\"\n",
    "        \n",
    "#         if self.bias:\n",
    "#             new_features = self._add_bias(new_features)\n",
    "#         return self.hypothesis(new_features, self.parameters_)\n",
    "    \n",
    "    \n",
    "#     def fit(self, features, label, parameters=None):\n",
    "#         \"\"\"Find the optimal parameters\n",
    "        \n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         features : 2d sequence of float\n",
    "#             The input parameters.\n",
    "#         label : 2d sequence of float\n",
    "#             The output parameters\n",
    "#         parameters : 2d sequence of float\n",
    "#             The initial guess for the descent gradient.\n",
    "#         \"\"\"\n",
    "#         # add bias or not\n",
    "#         if self.bias:\n",
    "#             features = self._add_bias(features)\n",
    "        \n",
    "#         # if no initial parameters are given get some randomly\n",
    "#         if parameters is None:\n",
    "#             n = features.shape[1]\n",
    "#             parameters = np.random.rand(n,1)\n",
    "    \n",
    "#         # compute the initial prediction\n",
    "#         predictions = self.hypothesis(features, parameters)\n",
    "        \n",
    "#         # solve depending of the regularization or not\n",
    "#         self.parameters_ = self._regularize_fit(features, label, parameters, predictions)\n",
    "\n",
    "    \n",
    "#     def _regularize_fit(self, features, label, parameters, predictions):\n",
    "#         \"\"\"Find the optimal parameters with regularized method\n",
    "#         \"\"\"\n",
    "\n",
    "#         m = features.shape[0]\n",
    "        \n",
    "#         lmb1 = 0.2\n",
    "#         if self.regularize == False:\n",
    "#             lmb1 = 0\n",
    "#         lmb2 = 0\n",
    "        \n",
    "#         if self.regularize == 'rigde':\n",
    "#             lmb2 = 0\n",
    "#         if self.regularize == 'lasso':\n",
    "#             lmb2 = 1\n",
    "#         if self.regularize == 'elastic-net':\n",
    "#             lmb2 = 0.4\n",
    "#         print('lambda 1 est ',lmb1)\n",
    "#         print('lambda 2 est ',lmb2)\n",
    "        \n",
    "        \n",
    "#         costFct = 0\n",
    "#         costFctEvol = []\n",
    "#         count = 0\n",
    "#         while self.testRegCostFct(predictions, label, lmb1, lmb2, parameters, costFct, self.epsilon):\n",
    "#             count += 1\n",
    "#             costFct = self.regCostFunction(predictions, label, lmb1, lmb2, parameters)\n",
    "#             grads = self.regGradients(predictions, label, features, lmb1, lmb2, parameters)\n",
    "#             parameters = self.updateParameters(parameters, grads, self.alpha)\n",
    "#             predictions = self.hypothesis(features, parameters)\n",
    "#             costFctEvol.append(costFct)\n",
    "            \n",
    "#         plt.xlabel('Iterations')\n",
    "#         plt.ylabel('Fonction cout')\n",
    "#         plt.title('Evolution de la fonction cout en fonctions des iterations')\n",
    "#         plt.plot(costFctEvol)\n",
    "#         return parameters\n",
    "    \n",
    "#     def _add_bias(self, features):\n",
    "#         \"\"\"Add bias column (1 vector)\n",
    "#         \"\"\"\n",
    "#         bias = np.ones(features.shape[0])\n",
    "#         return np.column_stack([features, bias])\n",
    "        \n",
    "#     def hypothesis(self, x, theta):\n",
    "#         \"\"\"Compute our hypothesis model (linear regression), use a fonction:\n",
    "#         \"\"\"\n",
    "#         return np.dot(x, theta)\n",
    "    \n",
    "#     def costFunction(self, yhat, y):\n",
    "#         \"\"\"Fonction de coût\n",
    "#         \"\"\"\n",
    "#         return np.square(yhat - y).sum() / (2*y.shape[0])\n",
    "    \n",
    "#     def regCostFunction(self, yhat, y, lmb1, lmb2, theta):\n",
    "#         \"\"\"Fonction de coût régularisée\n",
    "#         \"\"\"\n",
    "#         #return self.costFunction(yhat, y) + lmb1/((2*y.shape[0]) * np.square(theta)).sum()\n",
    "\n",
    "\n",
    "#         return self.costFunction(yhat, y) + lmb1*(((1-lmb2)/2) * np.square(theta).sum() + lmb2*(np.abs(theta)).sum())\n",
    "    \n",
    "#     def gradients(self, yhat, y, x):\n",
    "#         \"\"\"Dérivée de la fonction de coût == gradients\n",
    "#         \"\"\"\n",
    "        \n",
    "#         return (((yhat - y) * x).sum(axis=0) / x.shape[0]).reshape(x.shape[1],1)\n",
    "\n",
    "#     def regGradients(self, yhat, y, x, lmb1 ,lmb2 , theta):\n",
    "#         \"\"\"Dérivée de la fonction de coût regularisée\n",
    "#         \"\"\"\n",
    "#         #return (((yhat - y) * x).sum(axis=0) / x.shape[0]).reshape(x.shape[1],1) + lmb1/x.shape[0]*theta\n",
    "\n",
    "#         return (((yhat - y) * x).sum(axis=0) / x.shape[0]).reshape(x.shape[1],1) + (lmb1*(1-lmb2))/x.shape[0]*theta\n",
    "    \n",
    "#     def updateParameters(self, parameters, grads, alpha):\n",
    "#         \"\"\"Gradient descent: mise à jour des paramètres\n",
    "#         \"\"\"\n",
    "#         return parameters - alpha * grads\n",
    "    \n",
    "#     def testRegCostFct(self, yhat, y, lmb1, lmb2, theta, prevCostFct, epsilon):\n",
    "#         \"\"\" Fonction pour tester l'évolution de la fonction de coût régularisée\n",
    "            \n",
    "#             Returns\n",
    "#             -------\n",
    "#             test : bool\n",
    "#                 vrai = continuer la descente de gradient\n",
    "#         \"\"\"\n",
    "#         return np.abs(self.regCostFunction(yhat, y, lmb1, lmb2, theta) - prevCostFct) >= epsilon*prevCostFct\n",
    "    \n",
    "#     def train_test_split(self, X, y, ratio=0.3, random_seed = 42):\n",
    "#         \"\"\" Fonction pour subdiviser les donnees en donnees d'entrainement et donnees de test.\n",
    "        \n",
    "#              Parametres\n",
    "#             ----------\n",
    "#             X : 2d sequence of float\n",
    "#                 The input parameters.\n",
    "#             y : 2d sequence of float\n",
    "#                 The output parameters\n",
    "#             ratio : La ratio du test set.\n",
    "            \n",
    "#             Returns\n",
    "#             -------\n",
    "#             X_train : les features d'entrainement.\n",
    "#             y_train : les labels d'entrainement.\n",
    "#             X_test : les features de test.\n",
    "#             y_test : les labels de test.\n",
    "            \n",
    "#         \"\"\"\n",
    "#         X_train = []\n",
    "#         y_train = []\n",
    "#         X_test = []\n",
    "#         y_test = []\n",
    "#         rows = len(X)\n",
    "#         random.seed(random_seed)\n",
    "#         test_index = random.sample(range(0,rows), int(rows*ratio))\n",
    "#         for i in range(rows):\n",
    "#             if i in test_index:\n",
    "#                 X_test.append(X[i])\n",
    "#                 y_test.append(y[i])\n",
    "#             else:\n",
    "#                 X_train.append(X[i])\n",
    "#                 y_train.append(y[i])\n",
    "#         return np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "    \n",
    "#     def mae(self, y, y_pred) :\n",
    "#         return np.abs(y_pred - y).sum() / (2*y.shape[0])\n",
    "    \n",
    "#     def rmse(self, y, y_pred) :\n",
    "#         return np.sqrt(np.square(y_pred - y).sum() / (2*y.shape[0]))\n",
    "    \n",
    "#     def r2_score(self, y, y_pred) :\n",
    "#         return 1 - (np.square(y_pred - y).sum() / np.square(y_pred - np.mean(y)).sum())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "d4d33f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class GradientDescent():\n",
    "    \n",
    "    \"\"\"Ce module permet d'implementer une descente de gradient.\n",
    "    \n",
    "    Parametres\n",
    "    ----------\n",
    "    regularize : valeur possible (False, rigde, lasso, elasticNet)\n",
    "        False : effectue une descente de gradient classique sans regularisation.\n",
    "        rigde : effectue une descente de gradient avec regularisation Rigde.\n",
    "        lasso : effectue une descente de gradient avec regularisation Lasso.\n",
    "        elasticNet : permet d'effectuer une descente de gradient avec regularisation ElasticNet.\n",
    "    bias : bool\n",
    "        Si True, ajoute le biais sur les features.\n",
    "    learning_rate : float > 0\n",
    "        contitue le pas lors de la mise a jour des parametres.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    Cette classe vise à calculer les paramètres d'un modèle linéaire en utilisant\n",
    "    une méthode de descente de gradient avec ou sans régularisation..\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, regularize=False, bias=True, learning_rate=3e-9, normalize = False):\n",
    "        self.bias = bias\n",
    "        if learning_rate < 0:\n",
    "            raise ValueError('learning_rate parameter must be > 0. Here {}.'.format(learning_rate))\n",
    "        self.learning_rate = learning_rate\n",
    "        self.regularize = regularize\n",
    "        self.lambd = 0\n",
    "        self.alpha = 0\n",
    "        self.normalize = normalize\n",
    "        \n",
    "        \n",
    "        if self.regularize:    \n",
    "            self.epsilon = 1e-10\n",
    "            if self.regularize == 'ridge':\n",
    "                self.alpha = 0\n",
    "            elif self.regularize == 'lasso':\n",
    "                self.alpha = 1\n",
    "            elif self.regularize == 'elasticNet':\n",
    "                self.alpha = 0.4\n",
    "            else :\n",
    "                raise ValueError(\"le parametre 'regularize' ne peut prendre que : 'False', 'ridge', 'lasso', 'elasticNet'\")\n",
    "        else:\n",
    "            self.epsilon = 1e-8\n",
    "            self.lambd = 0\n",
    "            self.alpha = 0\n",
    "    \n",
    "    def predict(self, new_features):\n",
    "        \"\"\"Faire des prédictions en utilisant le résultat de la descente de gradient.\n",
    "        \n",
    "        Paramètres\n",
    "        ----------\n",
    "        new_features : matrice de flottants.\n",
    "            La caractéristique pour laquelle il faut prédire les étiquettes.\n",
    "            \n",
    "        Return\n",
    "        -------\n",
    "        predicted_labels : matrice de flottants.\n",
    "            les predictions du modele\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        La méthode fit doit être appelée en premier.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.bias:\n",
    "            new_features = self._add_bias(new_features)\n",
    "        return self.hypothesis(new_features, self.parameters_)\n",
    "    \n",
    "    \n",
    "    def fit(self, features, label, parameters=None, lambd=0, alpha=0):\n",
    "        \"\"\"Find the optimal parameters\n",
    "        \n",
    "        Parametres\n",
    "        ----------\n",
    "        features : matrice de flottants.\n",
    "            Les donnees d'entrainements.\n",
    "        label : matrice de flottants ou vecteur.\n",
    "            Le etiquettes des donnees d'entrainements.\n",
    "        parameters : matrice de flottants ou vecteur.\n",
    "            Les parametres du modele.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.normalize:\n",
    "            features = self.standardScaler(features)\n",
    "        # add bias or not\n",
    "        if self.bias:\n",
    "            features = self._add_bias(features)\n",
    "        \n",
    "        # if no initial parameters are given get some randomly\n",
    "        if parameters is None:\n",
    "            n = features.shape[1]\n",
    "            parameters = np.random.rand(n,1)\n",
    "    \n",
    "        # compute the initial prediction\n",
    "        predictions = self.hypothesis(features, parameters)\n",
    "        \n",
    "        # solve depending of the regularization or not\n",
    "        self.parameters_ = self._fit(features, label, parameters, predictions, self.lambd, self.alpha)\n",
    "\n",
    "    \n",
    "    def _fit(self, features, label, parameters, predictions, lambd, alpha):\n",
    "        \"\"\"Trouver les paramètres optimaux\n",
    "        \"\"\"\n",
    "\n",
    "        m = features.shape[0]\n",
    "   \n",
    "        if self.regularize == 'rigde':\n",
    "            self.lambd = lambd\n",
    "            if self.alpha != 0 :\n",
    "                raise ValueError(\"Le parametre 'alpha' ne concerne pas la regularisation Ridge\")\n",
    "            \n",
    "        elif self.regularize == 'lasso':\n",
    "            self.lambd = lambd\n",
    "            if self.alpha != 1:\n",
    "                raise ValueError(\"Le parametre 'alpha' ne concerne pas la regularisation Lasso\")\n",
    "                \n",
    "        elif self.regularize == 'elasticNet':\n",
    "            self.alpha = alpha\n",
    "            self.lambd = lambd\n",
    "\n",
    "    \n",
    "        \n",
    "        costFct = 0\n",
    "        costFctEvol = []\n",
    "        count = 0\n",
    "        while self.testCostFct(predictions, label, self.lambd, self.alpha, parameters, costFct, self.epsilon):\n",
    "            count += 1\n",
    "            costFct = self.costFunction(predictions, label, self.lambd, self.alpha, parameters)\n",
    "            grads = self.gradients(predictions, label, features, self.lambd, self.alpha, parameters)\n",
    "            parameters = self.updateParameters(parameters, grads, self.learning_rate)\n",
    "            predictions = self.hypothesis(features, parameters)\n",
    "            costFctEvol.append(costFct)\n",
    "            \n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Fonction cout')\n",
    "        plt.title('Evolution de la fonction cout en fonctions des iterations')\n",
    "        plt.plot(costFctEvol)\n",
    "        return parameters\n",
    "    \n",
    "    def _add_bias(self, features):\n",
    "        \"\"\"Ajouter une colonne de bias (1 vecteur)\n",
    "        \"\"\"\n",
    "        bias = np.ones(features.shape[0])\n",
    "        return np.column_stack([features, bias])\n",
    "        \n",
    "    def hypothesis(self, x, theta):\n",
    "        \"\"\"Calculer notre modèle d'hypothèse (régression linéaire), utiliser une fonction :\n",
    "        \"\"\"\n",
    "        return np.dot(x, theta)\n",
    "    \n",
    "    def _costFunction(self, yhat, y):\n",
    "        \"\"\"Fonction de coût\n",
    "        \"\"\"\n",
    "        return np.square(yhat - y).sum() / (2*y.shape[0])\n",
    "    def costFunction(self, yhat, y, lambd, alpha, theta):\n",
    "        \"\"\"Fonction de coût avec ou sans régularisée selon les parametres.\n",
    "        \"\"\"\n",
    "        return self._costFunction(yhat, y) + lambd*(((1-alpha)/2) * np.square(theta).sum() + alpha*(np.abs(theta)).sum())\n",
    "    \n",
    "\n",
    "\n",
    "    def gradients(self, yhat, y, x, lambd ,alpha , theta):\n",
    "        \"\"\"Dérivée de la fonction de coût\n",
    "        \"\"\"\n",
    "\n",
    "        return (((yhat - y) * x).sum(axis=0) / x.shape[0]).reshape(x.shape[1],1) + (lambd*(1-alpha))/x.shape[0]*theta\n",
    "    \n",
    "    def updateParameters(self, parameters, grads, learning_rate):\n",
    "        \"\"\"Gradient descent: mise à jour des paramètres\n",
    "        \"\"\"\n",
    "        return parameters - learning_rate * grads\n",
    "    \n",
    "    def testCostFct(self, yhat, y, lambd, alpha, theta, prevCostFct, epsilon):\n",
    "        \"\"\" Fonction pour tester l'évolution de la fonction de coût régularisée\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            test : bool\n",
    "                vrai = continuer la descente de gradient\n",
    "        \"\"\"\n",
    "        return np.abs(self.costFunction(yhat, y, lambd, alpha, theta) - prevCostFct) >= epsilon*prevCostFct\n",
    "        \n",
    "    \n",
    "    def train_test_split(self, X, y, ratio=0.3, random_seed = 42):\n",
    "        \"\"\" Fonction pour subdiviser les donnees en donnees d'entrainement et donnees de test.\n",
    "        \n",
    "             Parametres\n",
    "            ----------\n",
    "            X : matrice de flottants.\n",
    "            Les donnees d'entrainements.\n",
    "            \n",
    "            y : matrice de flottants ou vecteur.\n",
    "            Le etiquettes des donnees d'entrainements.\n",
    "            \n",
    "            ratio : La ratio du test set.\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            X_train : les features d'entrainement.\n",
    "            y_train : les labels d'entrainement.\n",
    "            X_test : les features de test.\n",
    "            y_test : les labels de test.\n",
    "            \n",
    "        \"\"\"\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        X_test = []\n",
    "        y_test = []\n",
    "        rows = len(X)\n",
    "        random.seed(random_seed)\n",
    "        test_index = random.sample(range(0,rows), int(rows*ratio))\n",
    "        for i in range(rows):\n",
    "            if i in test_index:\n",
    "                X_test.append(X[i])\n",
    "                y_test.append(y[i])\n",
    "            else:\n",
    "                X_train.append(X[i])\n",
    "                y_train.append(y[i])\n",
    "        return np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "    \n",
    "    def mae(self, y, y_pred) :\n",
    "        \"\"\" Fonction determiner le score Mean Absolute Error.\n",
    "        \n",
    "             Parametres\n",
    "            ----------\n",
    "            y : matrice de flottants ou vecteur.\n",
    "                Le etiquettes des donnees d'entrainements.\n",
    "            y_pred : matrice de flottants ou vecteur.\n",
    "                    valeurs predites par le modele.\n",
    "            \n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            score : flottant.\n",
    "                le score par la metric Mean Absolute Error.\n",
    "            \n",
    "        \"\"\"\n",
    "        return np.abs(y_pred - y).sum() / (2*y.shape[0])\n",
    "    \n",
    "    def rmse(self, y, y_pred) :\n",
    "        \n",
    "        \"\"\" Fonction determiner le score Root Mean Squared Error.\n",
    "        \n",
    "             Parametres\n",
    "            ----------\n",
    "            y : matrice de flottants ou vecteur.\n",
    "                Le etiquettes des donnees d'entrainements.\n",
    "            y_pred : matrice de flottants ou vecteur.\n",
    "                    valeurs predites par le modele.\n",
    "            \n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            score : flottant.\n",
    "                le score par la metric Root Mean Squared Error.\n",
    "            \n",
    "        \"\"\"\n",
    "        return np.sqrt(np.square(y_pred - y).sum() / (2*y.shape[0]))\n",
    "    \n",
    "    def r2_score(self, y, y_pred) :\n",
    "        \"\"\" Fonction determiner le score Coefficient de determination R2.\n",
    "        \n",
    "             Parametres\n",
    "            ----------\n",
    "            y : matrice de flottants ou vecteur.\n",
    "                Le etiquettes des donnees d'entrainements.\n",
    "            y_pred : matrice de flottants ou vecteur.\n",
    "                    valeurs predites par le modele.\n",
    "            \n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            score : flottant.\n",
    "                le score par la metric Coefficient de determination R2.\n",
    "            \n",
    "        \"\"\"\n",
    "        return 1 - (np.square(y_pred - y).sum() / np.square(y_pred - np.mean(y)).sum())\n",
    "    \n",
    "    def standardScaler(self, X):\n",
    "        \n",
    "        \"\"\" Fonction determiner le score Coefficient de determination R2.\n",
    "        \n",
    "             Parametres\n",
    "            ----------\n",
    "            X : matrice de flottants.\n",
    "                les donnees d'entrainements a normaliser.\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "             X : matrice de flottants.\n",
    "                les donnees normalisees ( centrees reduites ).\n",
    "            \n",
    "        \"\"\"\n",
    "        return np.array((X - X.mean(axis=0)) / (X.std(axis=0)))\n",
    "    def standardScaler(self, X):\n",
    "        \n",
    "        \"\"\" Fonction determiner le score Coefficient de determination R2.\n",
    "        \n",
    "             Parametres\n",
    "            ----------\n",
    "            X : matrice de flottants.\n",
    "                les donnees d'entrainements a normaliser.\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "             X : matrice de flottants.\n",
    "                les donnees normalisees ( centrees reduites ).\n",
    "            \n",
    "        \"\"\"\n",
    "        return np.array((X - X.mean(axis=0)) / (X.std(axis=0)))\n",
    "    \n",
    "    def tunning(self,X,y,scoring,nb_params=10, validation_ratio = 0.3):\n",
    "        \"\"\"Ce module determine les hyperparametres optimale de regularisations \n",
    "    \n",
    "        Parametres\n",
    "        ----------\n",
    "            X : matrice de flottants.\n",
    "                les features des donnees d'entrainements.\n",
    "            y: vecteur de flottants.\n",
    "                les features des donnees d'entrainements.\n",
    "            scoring : Le type de scoring pour evaluer les hyperparametres\n",
    "                valeurs possible ('mae', 'rmse', 'r2_score')\n",
    "            nb_params : Entier\n",
    "                le nombre de hyperparamtres a tester\n",
    "            validation_ratio : Flottant\n",
    "                le ratio du validation set.\n",
    "    \n",
    "        \"\"\"\n",
    "        if self.regularize == False:    \n",
    "            raise ValueError(\"Les hyperparametre de penalite s'applique uniquement sur une descent de gradient regularisee\")\n",
    "        else:\n",
    "            if scoring not in ['rmse','mae','r2_score']:\n",
    "                   raise ValueError(\"valeurs possible pour le scoring : 'mae', 'rmse', 'r2_score' \")\n",
    "            a_tester = np.arange(0.01,1,round(1/nb_params, 2))\n",
    "            X_train, y_train, X_validate, y_validate = g.train_test_split(X,y,ratio=validation_ratio)\n",
    "        \n",
    "            if self.regularize == 'ridge' or self.regularize == 'lasso':\n",
    "               \n",
    "                \n",
    "                if scoring == \"rmse\":\n",
    "                    best_score = 9e100\n",
    "                    best_param = 0\n",
    "    \n",
    "                    for i in a_tester:\n",
    "                        g.fit(X_train,y_train, lambd = i)\n",
    "                        y_pred = g.predict(X_validate)\n",
    "\n",
    "                        if scoring == \"rmse\":\n",
    "                            score = g.rmse(y_pred, y_validate)\n",
    "                            if score < best_score:\n",
    "                                best_score = score\n",
    "                                best_param = i\n",
    "                            \n",
    "    \n",
    "                    \n",
    "                elif scoring == \"mae\":\n",
    "                    best_score = 9e100\n",
    "                    best_param = 0\n",
    "    \n",
    "                    for i in a_tester:\n",
    "                        g.fit(X_train,y_train, lambd = i)\n",
    "                        y_pred = g.predict(X_validate)\n",
    "\n",
    "                        if scoring == \"mae\":\n",
    "                            score = g.mae(y_pred, y_validate)\n",
    "                            if score < best_score:\n",
    "                                best_score = score\n",
    "                                best_param = i\n",
    "                    \n",
    "                    \n",
    "                elif scoring == \"r2\":\n",
    "                    best_score = 0\n",
    "                    best_param = 0\n",
    "    \n",
    "                    for i in a_tester:\n",
    "                        g.fit(X_train,y_train, lambd = i)\n",
    "                        y_pred = g.predict(X_validate)\n",
    "\n",
    "                        if scoring == \"mae\":\n",
    "                            score = g.r2_score(y_pred, y_validate)\n",
    "                            if score > best_score:\n",
    "                                best_score = score\n",
    "                                best_param = i\n",
    "                print(\"Le meilleur parametre de penalite lambda : \",best_param)\n",
    "                    \n",
    "            elif self.regularize == 'elasticNet':\n",
    "                \n",
    "                if scoring == \"rmse\":\n",
    "                    best_score = 9e100\n",
    "                    best_param = 0\n",
    "    \n",
    "                    for i in a_tester:\n",
    "                        for j in a_tester:\n",
    "                            g.fit(X_train,y_train, lambd = i, alpha = j)\n",
    "                            y_pred = g.predict(X_validate)\n",
    "\n",
    "                            if scoring == \"rmse\":\n",
    "                                score = g.rmse(y_pred, y_validate)\n",
    "                                if score < best_score:\n",
    "                                    best_score = score\n",
    "                                    best_param = i , j\n",
    "        \n",
    "                    \n",
    "                elif scoring == \"mae\":\n",
    "                    best_score = 9e100\n",
    "                    best_param = 0\n",
    "    \n",
    "                    for i in a_tester:\n",
    "                        for j in a_tester:\n",
    "                            g.fit(X_train,y_train, lambd = i, alpha = j)\n",
    "                            y_pred = g.predict(X_validate)\n",
    "\n",
    "                            if scoring == \"mae\":\n",
    "                                score = g.mae(y_pred, y_validate)\n",
    "                                if score < best_score:\n",
    "                                    best_score = score\n",
    "                                    best_param = i , j\n",
    "                    \n",
    "                elif scoring == \"r2\":\n",
    "                    best_score = 0\n",
    "                    best_param = 0 , 0\n",
    "    \n",
    "                    for i in a_tester:\n",
    "                        for j in a_tester:\n",
    "                            g.fit(X_train,y_train, lambd = i, alpha = j)\n",
    "                            y_pred = g.predict(X_validate)\n",
    "\n",
    "                            if scoring == \"r2\":\n",
    "                                score = g.r2_score(y_pred, y_validate)\n",
    "                                if score > best_score:\n",
    "                                    best_score = score\n",
    "                                    best_param = i , j\n",
    "                print(\"Les meilleurs parametres de penalite pour la regularisation sont : lambda = \",best_param[0],\", alpha = \",best_param[1])               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "add28090",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = 0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "2a0cba73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "f1570194",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = GradientDescent(regularize = 'ridge',learning_rate = 0.03, normalize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "abdcd59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "np.random.seed(67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "f0119f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 3 * np.random.rand(100, 1) - 2\n",
    "Y = 2*X + 7 + np.random.randn(100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "ed743f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import load_diabetes\n",
    "# diabetes = load_diabetes()\n",
    "# X = diabetes.data\n",
    "# Y = diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "076261fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "9f1f89c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 > 9e100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "9ca49ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "64607514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = Y.reshape(-1,1)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "7b292cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.std(X, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "12c5fee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = g.train_test_split(X,Y,ratio=0.3,random_seed=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "42c72b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 1)"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "37dd4c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "a8aaf4a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.scatter(X_train,y_train,alpha = 0.7)\n",
    "# plt.xlabel('Features')\n",
    "# plt.ylabel('Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "6267ea40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0,1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "46162cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le meilleur parametre de penalite lambda :  0.51\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = g.tunning(X_train, y_train, \"mae\", nb_params=10, validation_ratio = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "ca0cfe3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "maxi = 0\n",
    "best = 0\n",
    "for i in lambd:\n",
    "    g.fit(X_train,y_train, lambd = i)\n",
    "    y_pred = g.predict(X_test)\n",
    "    score = g.rmse(y_pred, y_test)\n",
    "    if score > maxi:\n",
    "        maxi = score\n",
    "    best = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "6556715c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "92afd53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcd48fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope , intercept = g.parameters_[0][0],  g.parameters_[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0129c8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -24.62658308],\n",
       "       [-270.22196515],\n",
       "       [ 503.93855908],\n",
       "       [ 362.06748176],\n",
       "       [ -50.36962886],\n",
       "       [-125.34326717],\n",
       "       [-220.18345312],\n",
       "       [ 127.31801648],\n",
       "       [ 456.89968753],\n",
       "       [  42.21623661],\n",
       "       [ 152.0183723 ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.parameters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1306e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-24.626583078009983"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86b86228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.scatter(X,Y,alpha = 0.7)\n",
    "# plt.plot(X,X*slope+intercept, color = 'red')\n",
    "# plt.xlabel('Features')\n",
    "# plt.ylabel('Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0d5a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = g.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60d65130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5327425855215635"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.r2_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe978333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15be973b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
