{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b46a75a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import random\n",
    "\n",
    "\n",
    "# class GradientDescent():\n",
    "    \n",
    "#     \"\"\"Descent gradient class with regularize technique\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     regularize : bool\n",
    "#         If True, the regularization is used.\n",
    "#     bias : bool\n",
    "#         If the True, a bias is added to the features.\n",
    "#     alpha : float > 0\n",
    "#         Coefficient for the step when updating the parameters.\n",
    "    \n",
    "#     Notes\n",
    "#     -----\n",
    "#     This class aims at computing the parameters of a linear model using\n",
    "#     a descent gradient method with or without regularization.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def __init__(self, regularize=False, bias=True, alpha=3e-9, iterations=30000):\n",
    "#         self.bias = bias\n",
    "#         if alpha < 0:\n",
    "#             raise ValueError('Alpha parameter must be > 0. Here {}.'.format(alpha))\n",
    "#         self.alpha = alpha\n",
    "#         self.iterations = iterations\n",
    "#         self.regularize = regularize\n",
    "        \n",
    "#         #set the epsilon value depending on the regularize case\n",
    "#         if regularize:\n",
    "#             self.epsilon = 1e-10\n",
    "#         else:\n",
    "#             self.epsilon = 1e-8\n",
    "    \n",
    "#     def predict(self, new_features):\n",
    "#         \"\"\"Make predictions using the result of the gradient descent\n",
    "        \n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         new_features : 2d sequence of float\n",
    "#             The feature for which to predict the labels.\n",
    "            \n",
    "#         Returns\n",
    "#         -------\n",
    "#         predicted_labels : 2d sequence of float\n",
    "#             The predicted labels\n",
    "        \n",
    "#         Notes\n",
    "#         -----\n",
    "#         The method fit must be called first.\n",
    "#         \"\"\"\n",
    "        \n",
    "#         if self.bias:\n",
    "#             new_features = self._add_bias(new_features)\n",
    "#         return self.hypothesis(new_features, self.parameters_)\n",
    "    \n",
    "    \n",
    "#     def fit(self, features, label, parameters=None):\n",
    "#         \"\"\"Find the optimal parameters\n",
    "        \n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         features : 2d sequence of float\n",
    "#             The input parameters.\n",
    "#         label : 2d sequence of float\n",
    "#             The output parameters\n",
    "#         parameters : 2d sequence of float\n",
    "#             The initial guess for the descent gradient.\n",
    "#         \"\"\"\n",
    "#         # add bias or not\n",
    "#         if self.bias:\n",
    "#             features = self._add_bias(features)\n",
    "        \n",
    "#         # if no initial parameters are given get some randomly\n",
    "#         if parameters is None:\n",
    "#             n = features.shape[1]\n",
    "#             parameters = np.random.rand(n,1)\n",
    "    \n",
    "#         # compute the initial prediction\n",
    "#         predictions = self.hypothesis(features, parameters)\n",
    "        \n",
    "#         # solve depending of the regularization or not\n",
    "#         self.parameters_ = self._regularize_fit(features, label, parameters, predictions)\n",
    "\n",
    "    \n",
    "#     def _regularize_fit(self, features, label, parameters, predictions):\n",
    "#         \"\"\"Find the optimal parameters with regularized method\n",
    "#         \"\"\"\n",
    "\n",
    "#         m = features.shape[0]\n",
    "        \n",
    "#         lmb1 = 0.2\n",
    "#         if self.regularize == False:\n",
    "#             lmb1 = 0\n",
    "#         lmb2 = 0\n",
    "        \n",
    "#         if self.regularize == 'rigde':\n",
    "#             lmb2 = 0\n",
    "#         if self.regularize == 'lasso':\n",
    "#             lmb2 = 1\n",
    "#         if self.regularize == 'elastic-net':\n",
    "#             lmb2 = 0.4\n",
    "#         print('lambda 1 est ',lmb1)\n",
    "#         print('lambda 2 est ',lmb2)\n",
    "        \n",
    "        \n",
    "#         costFct = 0\n",
    "#         costFctEvol = []\n",
    "#         count = 0\n",
    "#         while self.testRegCostFct(predictions, label, lmb1, lmb2, parameters, costFct, self.epsilon):\n",
    "#             count += 1\n",
    "#             costFct = self.regCostFunction(predictions, label, lmb1, lmb2, parameters)\n",
    "#             grads = self.regGradients(predictions, label, features, lmb1, lmb2, parameters)\n",
    "#             parameters = self.updateParameters(parameters, grads, self.alpha)\n",
    "#             predictions = self.hypothesis(features, parameters)\n",
    "#             costFctEvol.append(costFct)\n",
    "            \n",
    "#         plt.xlabel('Iterations')\n",
    "#         plt.ylabel('Fonction cout')\n",
    "#         plt.title('Evolution de la fonction cout en fonctions des iterations')\n",
    "#         plt.plot(costFctEvol)\n",
    "#         return parameters\n",
    "    \n",
    "#     def _add_bias(self, features):\n",
    "#         \"\"\"Add bias column (1 vector)\n",
    "#         \"\"\"\n",
    "#         bias = np.ones(features.shape[0])\n",
    "#         return np.column_stack([features, bias])\n",
    "        \n",
    "#     def hypothesis(self, x, theta):\n",
    "#         \"\"\"Compute our hypothesis model (linear regression), use a fonction:\n",
    "#         \"\"\"\n",
    "#         return np.dot(x, theta)\n",
    "    \n",
    "#     def costFunction(self, yhat, y):\n",
    "#         \"\"\"Fonction de coût\n",
    "#         \"\"\"\n",
    "#         return np.square(yhat - y).sum() / (2*y.shape[0])\n",
    "    \n",
    "#     def regCostFunction(self, yhat, y, lmb1, lmb2, theta):\n",
    "#         \"\"\"Fonction de coût régularisée\n",
    "#         \"\"\"\n",
    "#         #return self.costFunction(yhat, y) + lmb1/((2*y.shape[0]) * np.square(theta)).sum()\n",
    "\n",
    "\n",
    "#         return self.costFunction(yhat, y) + lmb1*(((1-lmb2)/2) * np.square(theta).sum() + lmb2*(np.abs(theta)).sum())\n",
    "    \n",
    "#     def gradients(self, yhat, y, x):\n",
    "#         \"\"\"Dérivée de la fonction de coût == gradients\n",
    "#         \"\"\"\n",
    "        \n",
    "#         return (((yhat - y) * x).sum(axis=0) / x.shape[0]).reshape(x.shape[1],1)\n",
    "\n",
    "#     def regGradients(self, yhat, y, x, lmb1 ,lmb2 , theta):\n",
    "#         \"\"\"Dérivée de la fonction de coût regularisée\n",
    "#         \"\"\"\n",
    "#         #return (((yhat - y) * x).sum(axis=0) / x.shape[0]).reshape(x.shape[1],1) + lmb1/x.shape[0]*theta\n",
    "\n",
    "#         return (((yhat - y) * x).sum(axis=0) / x.shape[0]).reshape(x.shape[1],1) + (lmb1*(1-lmb2))/x.shape[0]*theta\n",
    "    \n",
    "#     def updateParameters(self, parameters, grads, alpha):\n",
    "#         \"\"\"Gradient descent: mise à jour des paramètres\n",
    "#         \"\"\"\n",
    "#         return parameters - alpha * grads\n",
    "    \n",
    "#     def testRegCostFct(self, yhat, y, lmb1, lmb2, theta, prevCostFct, epsilon):\n",
    "#         \"\"\" Fonction pour tester l'évolution de la fonction de coût régularisée\n",
    "            \n",
    "#             Returns\n",
    "#             -------\n",
    "#             test : bool\n",
    "#                 vrai = continuer la descente de gradient\n",
    "#         \"\"\"\n",
    "#         return np.abs(self.regCostFunction(yhat, y, lmb1, lmb2, theta) - prevCostFct) >= epsilon*prevCostFct\n",
    "    \n",
    "#     def train_test_split(self, X, y, ratio=0.3, random_seed = 42):\n",
    "#         \"\"\" Fonction pour subdiviser les donnees en donnees d'entrainement et donnees de test.\n",
    "        \n",
    "#              Parametres\n",
    "#             ----------\n",
    "#             X : 2d sequence of float\n",
    "#                 The input parameters.\n",
    "#             y : 2d sequence of float\n",
    "#                 The output parameters\n",
    "#             ratio : La ratio du test set.\n",
    "            \n",
    "#             Returns\n",
    "#             -------\n",
    "#             X_train : les features d'entrainement.\n",
    "#             y_train : les labels d'entrainement.\n",
    "#             X_test : les features de test.\n",
    "#             y_test : les labels de test.\n",
    "            \n",
    "#         \"\"\"\n",
    "#         X_train = []\n",
    "#         y_train = []\n",
    "#         X_test = []\n",
    "#         y_test = []\n",
    "#         rows = len(X)\n",
    "#         random.seed(random_seed)\n",
    "#         test_index = random.sample(range(0,rows), int(rows*ratio))\n",
    "#         for i in range(rows):\n",
    "#             if i in test_index:\n",
    "#                 X_test.append(X[i])\n",
    "#                 y_test.append(y[i])\n",
    "#             else:\n",
    "#                 X_train.append(X[i])\n",
    "#                 y_train.append(y[i])\n",
    "#         return np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "    \n",
    "#     def mae(self, y, y_pred) :\n",
    "#         return np.abs(y_pred - y).sum() / (2*y.shape[0])\n",
    "    \n",
    "#     def rmse(self, y, y_pred) :\n",
    "#         return np.sqrt(np.square(y_pred - y).sum() / (2*y.shape[0]))\n",
    "    \n",
    "#     def r2_score(self, y, y_pred) :\n",
    "#         return 1 - (np.square(y_pred - y).sum() / np.square(y_pred - np.mean(y)).sum())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "6176afc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class GradientDescent():\n",
    "    \n",
    "    \"\"\"Ce module permet d'implementer une descente de gradient.\n",
    "    \n",
    "    Parametres\n",
    "    ----------\n",
    "    regularize : valeur possible (False, rigde, lasso, elasticNet)\n",
    "        False : effectue une descente de gradient classique sans regularisation.\n",
    "        rigde : effectue une descente de gradient avec regularisation Rigde.\n",
    "        lasso : effectue une descente de gradient avec regularisation Lasso.\n",
    "        elasticNet : permet d'effectuer une descente de gradient avec regularisation ElasticNet.\n",
    "    bias : bool\n",
    "        Si True, ajoute le biais sur les features.\n",
    "    learning_rate : float > 0\n",
    "        contitue le pas lors de la mise a jour des parametres.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    Cette classe vise à calculer les paramètres d'un modèle linéaire en utilisant\n",
    "    une méthode de descente de gradient avec ou sans régularisation..\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, regularize=False, bias=True, learning_rate=3e-9, normalize = False):\n",
    "        self.bias = bias\n",
    "        if learning_rate < 0:\n",
    "            raise ValueError('learning_rate parameter must be > 0. Here {}.'.format(learning_rate))\n",
    "        self.learning_rate = learning_rate\n",
    "        self.regularize = regularize\n",
    "        self.lambd = 0\n",
    "        self.alpha = 0\n",
    "        self.normalize = normalize\n",
    "        \n",
    "        \n",
    "        if self.regularize:    \n",
    "            self.epsilon = 1e-10\n",
    "            if self.regularize == 'ridge':\n",
    "                self.alpha = 0\n",
    "            elif self.regularize == 'lasso':\n",
    "                self.alpha = 1\n",
    "            elif self.regularize == 'elasticNet':\n",
    "                self.alpha = 0.4\n",
    "            else :\n",
    "                raise ValueError(\"le parametre 'regularize' ne peut prendre que : 'False', 'ridge', 'lasso', 'elasticNet'\")\n",
    "        else:\n",
    "            self.epsilon = 1e-8\n",
    "            self.lambd = 0\n",
    "            self.alpha = 0\n",
    "    \n",
    "    def predict(self, new_features):\n",
    "        \"\"\"Faire des prédictions en utilisant le résultat de la descente de gradient.\n",
    "        \n",
    "        Paramètres\n",
    "        ----------\n",
    "        new_features : matrice de flottants.\n",
    "            La caractéristique pour laquelle il faut prédire les étiquettes.\n",
    "            \n",
    "        Return\n",
    "        -------\n",
    "        predicted_labels : matrice de flottants.\n",
    "            les predictions du modele\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        La méthode fit doit être appelée en premier.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.bias:\n",
    "            new_features = self._add_bias(new_features)\n",
    "        return self.hypothesis(new_features, self.parameters_)\n",
    "    \n",
    "    \n",
    "    def fit(self, features, label, parameters=None, lambd=0, alpha=0):\n",
    "        \"\"\"Find the optimal parameters\n",
    "        \n",
    "        Parametres\n",
    "        ----------\n",
    "        features : matrice de flottants.\n",
    "            Les donnees d'entrainements.\n",
    "        label : matrice de flottants ou vecteur.\n",
    "            Le etiquettes des donnees d'entrainements.\n",
    "        parameters : matrice de flottants ou vecteur.\n",
    "            Les parametres du modele.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.normalize:\n",
    "            features = self.standardScaler(features)\n",
    "        # add bias or not\n",
    "        if self.bias:\n",
    "            features = self._add_bias(features)\n",
    "        \n",
    "        # if no initial parameters are given get some randomly\n",
    "        if parameters is None:\n",
    "            n = features.shape[1]\n",
    "            parameters = np.random.rand(n,1)\n",
    "    \n",
    "        # compute the initial prediction\n",
    "        predictions = self.hypothesis(features, parameters)\n",
    "        \n",
    "        # solve depending of the regularization or not\n",
    "        self.parameters_ = self._fit(features, label, parameters, predictions, self.lambd, self.alpha)\n",
    "\n",
    "    \n",
    "    def _fit(self, features, label, parameters, predictions, lambd, alpha):\n",
    "        \"\"\"Trouver les paramètres optimaux\n",
    "        \"\"\"\n",
    "\n",
    "        m = features.shape[0]\n",
    "   \n",
    "        if self.regularize == 'rigde':\n",
    "            self.lambd = lambd\n",
    "            if self.alpha != 0 :\n",
    "                raise ValueError(\"Le parametre 'alpha' ne concerne pas la regularisation Ridge\")\n",
    "            \n",
    "        elif self.regularize == 'lasso':\n",
    "            self.lambd = lambd\n",
    "            if self.alpha != 1:\n",
    "                raise ValueError(\"Le parametre 'alpha' ne concerne pas la regularisation Lasso\")\n",
    "                \n",
    "        elif self.regularize == 'elasticNet':\n",
    "            self.alpha = alpha\n",
    "            self.lambd = lambd\n",
    "\n",
    "    \n",
    "        \n",
    "        costFct = 0\n",
    "        costFctEvol = []\n",
    "        count = 0\n",
    "        while self.testCostFct(predictions, label, self.lambd, self.alpha, parameters, costFct, self.epsilon):\n",
    "            count += 1\n",
    "            costFct = self.costFunction(predictions, label, self.lambd, self.alpha, parameters)\n",
    "            grads = self.gradients(predictions, label, features, self.lambd, self.alpha, parameters)\n",
    "            parameters = self.updateParameters(parameters, grads, self.learning_rate)\n",
    "            predictions = self.hypothesis(features, parameters)\n",
    "            costFctEvol.append(costFct)\n",
    "            \n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Fonction cout')\n",
    "        plt.title('Evolution de la fonction cout en fonctions des iterations')\n",
    "        plt.plot(costFctEvol)\n",
    "        return parameters\n",
    "    \n",
    "    def _add_bias(self, features):\n",
    "        \"\"\"Ajouter une colonne de bias (1 vecteur)\n",
    "        \"\"\"\n",
    "        bias = np.ones(features.shape[0])\n",
    "        return np.column_stack([features, bias])\n",
    "        \n",
    "    def hypothesis(self, x, theta):\n",
    "        \"\"\"Calculer notre modèle d'hypothèse (régression linéaire), utiliser une fonction :\n",
    "        \"\"\"\n",
    "        return np.dot(x, theta)\n",
    "    \n",
    "    def _costFunction(self, yhat, y):\n",
    "        \"\"\"Fonction de coût\n",
    "        \"\"\"\n",
    "        return np.square(yhat - y).sum() / (2*y.shape[0])\n",
    "    def costFunction(self, yhat, y, lambd, alpha, theta):\n",
    "        \"\"\"Fonction de coût avec ou sans régularisée selon les parametres.\n",
    "        \"\"\"\n",
    "        return self._costFunction(yhat, y) + lambd*(((1-alpha)/2) * np.square(theta).sum() + alpha*(np.abs(theta)).sum())\n",
    "    \n",
    "\n",
    "\n",
    "    def gradients(self, yhat, y, x, lambd ,alpha , theta):\n",
    "        \"\"\"Dérivée de la fonction de coût\n",
    "        \"\"\"\n",
    "\n",
    "        return (((yhat - y) * x).sum(axis=0) / x.shape[0]).reshape(x.shape[1],1) + (lambd*(1-alpha))/x.shape[0]*theta\n",
    "    \n",
    "    def updateParameters(self, parameters, grads, learning_rate):\n",
    "        \"\"\"Gradient descent: mise à jour des paramètres\n",
    "        \"\"\"\n",
    "        return parameters - learning_rate * grads\n",
    "    \n",
    "    def testCostFct(self, yhat, y, lambd, alpha, theta, prevCostFct, epsilon):\n",
    "        \"\"\" Fonction pour tester l'évolution de la fonction de coût régularisée\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            test : bool\n",
    "                vrai = continuer la descente de gradient\n",
    "        \"\"\"\n",
    "        return np.abs(self.costFunction(yhat, y, lambd, alpha, theta) - prevCostFct) >= epsilon*prevCostFct\n",
    "        \n",
    "    \n",
    "    def train_test_split(self, X, y, ratio=0.3, random_seed = 42):\n",
    "        \"\"\" Fonction pour subdiviser les donnees en donnees d'entrainement et donnees de test.\n",
    "        \n",
    "             Parametres\n",
    "            ----------\n",
    "            X : matrice de flottants.\n",
    "            Les donnees d'entrainements.\n",
    "            \n",
    "            y : matrice de flottants ou vecteur.\n",
    "            Le etiquettes des donnees d'entrainements.\n",
    "            \n",
    "            ratio : La ratio du test set.\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            X_train : les features d'entrainement.\n",
    "            y_train : les labels d'entrainement.\n",
    "            X_test : les features de test.\n",
    "            y_test : les labels de test.\n",
    "            \n",
    "        \"\"\"\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        X_test = []\n",
    "        y_test = []\n",
    "        rows = len(X)\n",
    "        random.seed(random_seed)\n",
    "        test_index = random.sample(range(0,rows), int(rows*ratio))\n",
    "        for i in range(rows):\n",
    "            if i in test_index:\n",
    "                X_test.append(X[i])\n",
    "                y_test.append(y[i])\n",
    "            else:\n",
    "                X_train.append(X[i])\n",
    "                y_train.append(y[i])\n",
    "        return np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "    \n",
    "    def mae(self, y, y_pred) :\n",
    "        \"\"\" Fonction determiner le score Mean Absolute Error.\n",
    "        \n",
    "             Parametres\n",
    "            ----------\n",
    "            y : matrice de flottants ou vecteur.\n",
    "                Le etiquettes des donnees d'entrainements.\n",
    "            y_pred : matrice de flottants ou vecteur.\n",
    "                    valeurs predites par le modele.\n",
    "            \n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            score : flottant.\n",
    "                le score par la metric Mean Absolute Error.\n",
    "            \n",
    "        \"\"\"\n",
    "        return np.abs(y_pred - y).sum() / (2*y.shape[0])\n",
    "    \n",
    "    def rmse(self, y, y_pred) :\n",
    "        \n",
    "        \"\"\" Fonction determiner le score Root Mean Squared Error.\n",
    "        \n",
    "             Parametres\n",
    "            ----------\n",
    "            y : matrice de flottants ou vecteur.\n",
    "                Le etiquettes des donnees d'entrainements.\n",
    "            y_pred : matrice de flottants ou vecteur.\n",
    "                    valeurs predites par le modele.\n",
    "            \n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            score : flottant.\n",
    "                le score par la metric Root Mean Squared Error.\n",
    "            \n",
    "        \"\"\"\n",
    "        return np.sqrt(np.square(y_pred - y).sum() / (2*y.shape[0]))\n",
    "    \n",
    "    def r2_score(self, y, y_pred) :\n",
    "        \"\"\" Fonction determiner le score Coefficient de determination R2.\n",
    "        \n",
    "             Parametres\n",
    "            ----------\n",
    "            y : matrice de flottants ou vecteur.\n",
    "                Le etiquettes des donnees d'entrainements.\n",
    "            y_pred : matrice de flottants ou vecteur.\n",
    "                    valeurs predites par le modele.\n",
    "            \n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            score : flottant.\n",
    "                le score par la metric Coefficient de determination R2.\n",
    "            \n",
    "        \"\"\"\n",
    "        return 1 - (np.square(y_pred - y).sum() / np.square(y_pred - np.mean(y)).sum())\n",
    "    \n",
    "    def standardScaler(self, X):\n",
    "        \n",
    "        \"\"\" Fonction determiner le score Coefficient de determination R2.\n",
    "        \n",
    "             Parametres\n",
    "            ----------\n",
    "            X : matrice de flottants.\n",
    "                les donnees d'entrainements a normaliser.\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "             X : matrice de flottants.\n",
    "                les donnees normalisees ( centrees reduites ).\n",
    "            \n",
    "        \"\"\"\n",
    "        return np.array((X - X.mean(axis=0)) / (X.std(axis=0)))\n",
    "    def standardScaler(self, X):\n",
    "        \n",
    "        \"\"\" Fonction determiner le score Coefficient de determination R2.\n",
    "        \n",
    "             Parametres\n",
    "            ----------\n",
    "            X : matrice de flottants.\n",
    "                les donnees d'entrainements a normaliser.\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "             X : matrice de flottants.\n",
    "                les donnees normalisees ( centrees reduites ).\n",
    "            \n",
    "        \"\"\"\n",
    "        return np.array((X - X.mean(axis=0)) / (X.std(axis=0)))\n",
    "    \n",
    "    def tunning(self,X,y,scoring,nb_params=10, validation_ratio = 0.3):\n",
    "        \"\"\"Ce module determine les hyperparametres optimale de regularisations \n",
    "    \n",
    "        Parametres\n",
    "        ----------\n",
    "            X : matrice de flottants.\n",
    "                les features des donnees d'entrainements.\n",
    "            y: vecteur de flottants.\n",
    "                les features des donnees d'entrainements.\n",
    "            scoring : Le type de scoring pour evaluer les hyperparametres\n",
    "                valeurs possible ('mae', 'rmse', 'r2_score')\n",
    "            nb_params : Entier\n",
    "                le nombre de hyperparamtres a tester\n",
    "            validation_ratio : Flottant\n",
    "                le ratio du validation set.\n",
    "    \n",
    "        \"\"\"\n",
    "        if self.regularize == False:    \n",
    "            raise ValueError(\"Les hyperparametre de penalite s'applique uniquement sur une descent de gradient regularisee\")\n",
    "        else:\n",
    "            if scoring not in ['rmse','mae','r2_score']:\n",
    "                   raise ValueError(\"valeurs possible pour le scoring : 'mae', 'rmse', 'r2_score' \")\n",
    "            a_tester = np.arange(0.01,1,round(1/nb_params, 2))\n",
    "            X_train, y_train, X_validate, y_validate = g.train_test_split(X,y,ratio=validation_ratio)\n",
    "        \n",
    "            if self.regularize == 'ridge' or self.regularize == 'lasso':\n",
    "               \n",
    "                \n",
    "                if scoring == \"rmse\":\n",
    "                    best_score = 9e100\n",
    "                    best_param = 0\n",
    "    \n",
    "                    for i in a_tester:\n",
    "                        g.fit(X_train,y_train, lambd = i)\n",
    "                        y_pred = g.predict(X_validate)\n",
    "\n",
    "                        if scoring == \"rmse\":\n",
    "                            score = g.rmse(y_pred, y_validate)\n",
    "                            if score < best_score:\n",
    "                                best_score = score\n",
    "                                best_param = i\n",
    "                            \n",
    "    \n",
    "                    \n",
    "                elif scoring == \"mae\":\n",
    "                    best_score = 9e100\n",
    "                    best_param = 0\n",
    "    \n",
    "                    for i in a_tester:\n",
    "                        g.fit(X_train,y_train, lambd = i)\n",
    "                        y_pred = g.predict(X_validate)\n",
    "\n",
    "                        if scoring == \"mae\":\n",
    "                            score = g.mae(y_pred, y_validate)\n",
    "                            if score < best_score:\n",
    "                                best_score = score\n",
    "                                best_param = i\n",
    "                    \n",
    "                    \n",
    "                elif scoring == \"r2\":\n",
    "                    best_score = 0\n",
    "                    best_param = 0\n",
    "    \n",
    "                    for i in a_tester:\n",
    "                        g.fit(X_train,y_train, lambd = i)\n",
    "                        y_pred = g.predict(X_validate)\n",
    "\n",
    "                        if scoring == \"mae\":\n",
    "                            score = g.r2_score(y_pred, y_validate)\n",
    "                            if score > best_score:\n",
    "                                best_score = score\n",
    "                                best_param = i\n",
    "                print(\"Le meilleur parametre de penalite lambda : \",best_param)\n",
    "                    \n",
    "            elif self.regularize == 'elasticNet':\n",
    "                \n",
    "                if scoring == \"rmse\":\n",
    "                    best_score = 9e100\n",
    "                    best_param = 0\n",
    "    \n",
    "                    for i in a_tester:\n",
    "                        for j in a_tester:\n",
    "                            g.fit(X_train,y_train, lambd = i, alpha = j)\n",
    "                            y_pred = g.predict(X_validate)\n",
    "\n",
    "                            if scoring == \"rmse\":\n",
    "                                score = g.rmse(y_pred, y_validate)\n",
    "                                if score < best_score:\n",
    "                                    best_score = score\n",
    "                                    best_param = i , j\n",
    "        \n",
    "                    \n",
    "                elif scoring == \"mae\":\n",
    "                    best_score = 9e100\n",
    "                    best_param = 0\n",
    "    \n",
    "                    for i in a_tester:\n",
    "                        for j in a_tester:\n",
    "                            g.fit(X_train,y_train, lambd = i, alpha = j)\n",
    "                            y_pred = g.predict(X_validate)\n",
    "\n",
    "                            if scoring == \"mae\":\n",
    "                                score = g.mae(y_pred, y_validate)\n",
    "                                if score < best_score:\n",
    "                                    best_score = score\n",
    "                                    best_param = i , j\n",
    "                    \n",
    "                elif scoring == \"r2\":\n",
    "                    best_score = 0\n",
    "                    best_param = 0 , 0\n",
    "    \n",
    "                    for i in a_tester:\n",
    "                        for j in a_tester:\n",
    "                            g.fit(X_train,y_train, lambd = i, alpha = j)\n",
    "                            y_pred = g.predict(X_validate)\n",
    "\n",
    "                            if scoring == \"r2\":\n",
    "                                score = g.r2_score(y_pred, y_validate)\n",
    "                                if score > best_score:\n",
    "                                    best_score = score\n",
    "                                    best_param = i , j\n",
    "                print(\"Les meilleurs parametres de penalite pour la regularisation sont : lambda = \",best_param[0],\", alpha = \",best_param[1])               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "8c47d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = 0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "06476cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "17630df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = GradientDescent(regularize = 'ridge',learning_rate = 0.03, normalize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "6ae1d966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "np.random.seed(67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "237211bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 3 * np.random.rand(100, 1) - 2\n",
    "Y = 2*X + 7 + np.random.randn(100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "d264cf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import load_diabetes\n",
    "# diabetes = load_diabetes()\n",
    "# X = diabetes.data\n",
    "# Y = diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "22daa386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "2e37d3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 > 9e100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "2ac7d18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "bc39cc07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = Y.reshape(-1,1)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "82337f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.std(X, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "9e976b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = g.train_test_split(X,Y,ratio=0.3,random_seed=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "ca02ebc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 1)"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "2bffaf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "08f15c2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.scatter(X_train,y_train,alpha = 0.7)\n",
    "# plt.xlabel('Features')\n",
    "# plt.ylabel('Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "a8ddb24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0,1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "6f24460d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le meilleur parametre de penalite lambda :  0.51\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = g.tunning(X_train, y_train, \"mae\", nb_params=10, validation_ratio = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "ae9e8592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "maxi = 0\n",
    "best = 0\n",
    "for i in lambd:\n",
    "    g.fit(X_train,y_train, lambd = i)\n",
    "    y_pred = g.predict(X_test)\n",
    "    score = g.rmse(y_pred, y_test)\n",
    "    if score > maxi:\n",
    "        maxi = score\n",
    "    best = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "a90282a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "afb1a361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6309b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope , intercept = g.parameters_[0][0],  g.parameters_[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a038c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -24.62658308],\n",
       "       [-270.22196515],\n",
       "       [ 503.93855908],\n",
       "       [ 362.06748176],\n",
       "       [ -50.36962886],\n",
       "       [-125.34326717],\n",
       "       [-220.18345312],\n",
       "       [ 127.31801648],\n",
       "       [ 456.89968753],\n",
       "       [  42.21623661],\n",
       "       [ 152.0183723 ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.parameters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea7c4baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-24.626583078009983"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7be3fe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.scatter(X,Y,alpha = 0.7)\n",
    "# plt.plot(X,X*slope+intercept, color = 'red')\n",
    "# plt.xlabel('Features')\n",
    "# plt.ylabel('Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f60e7b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = g.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "134e8ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5327425855215635"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.r2_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ebab82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73876da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
