{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b46a75a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import random\n",
    "\n",
    "\n",
    "# class GradientDescent():\n",
    "    \n",
    "#     \"\"\"Descent gradient class with regularize technique\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     regularize : bool\n",
    "#         If True, the regularization is used.\n",
    "#     bias : bool\n",
    "#         If the True, a bias is added to the features.\n",
    "#     alpha : float > 0\n",
    "#         Coefficient for the step when updating the parameters.\n",
    "    \n",
    "#     Notes\n",
    "#     -----\n",
    "#     This class aims at computing the parameters of a linear model using\n",
    "#     a descent gradient method with or without regularization.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def __init__(self, regularize=False, bias=True, alpha=3e-9, iterations=30000):\n",
    "#         self.bias = bias\n",
    "#         if alpha < 0:\n",
    "#             raise ValueError('Alpha parameter must be > 0. Here {}.'.format(alpha))\n",
    "#         self.alpha = alpha\n",
    "#         self.iterations = iterations\n",
    "#         self.regularize = regularize\n",
    "        \n",
    "#         #set the epsilon value depending on the regularize case\n",
    "#         if regularize:\n",
    "#             self.epsilon = 1e-10\n",
    "#         else:\n",
    "#             self.epsilon = 1e-8\n",
    "    \n",
    "#     def predict(self, new_features):\n",
    "#         \"\"\"Make predictions using the result of the gradient descent\n",
    "        \n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         new_features : 2d sequence of float\n",
    "#             The feature for which to predict the labels.\n",
    "            \n",
    "#         Returns\n",
    "#         -------\n",
    "#         predicted_labels : 2d sequence of float\n",
    "#             The predicted labels\n",
    "        \n",
    "#         Notes\n",
    "#         -----\n",
    "#         The method fit must be called first.\n",
    "#         \"\"\"\n",
    "        \n",
    "#         if self.bias:\n",
    "#             new_features = self._add_bias(new_features)\n",
    "#         return self.hypothesis(new_features, self.parameters_)\n",
    "    \n",
    "    \n",
    "#     def fit(self, features, label, parameters=None):\n",
    "#         \"\"\"Find the optimal parameters\n",
    "        \n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         features : 2d sequence of float\n",
    "#             The input parameters.\n",
    "#         label : 2d sequence of float\n",
    "#             The output parameters\n",
    "#         parameters : 2d sequence of float\n",
    "#             The initial guess for the descent gradient.\n",
    "#         \"\"\"\n",
    "#         # add bias or not\n",
    "#         if self.bias:\n",
    "#             features = self._add_bias(features)\n",
    "        \n",
    "#         # if no initial parameters are given get some randomly\n",
    "#         if parameters is None:\n",
    "#             n = features.shape[1]\n",
    "#             parameters = np.random.rand(n,1)\n",
    "    \n",
    "#         # compute the initial prediction\n",
    "#         predictions = self.hypothesis(features, parameters)\n",
    "        \n",
    "#         # solve depending of the regularization or not\n",
    "#         self.parameters_ = self._regularize_fit(features, label, parameters, predictions)\n",
    "\n",
    "    \n",
    "#     def _regularize_fit(self, features, label, parameters, predictions):\n",
    "#         \"\"\"Find the optimal parameters with regularized method\n",
    "#         \"\"\"\n",
    "\n",
    "#         m = features.shape[0]\n",
    "        \n",
    "#         lmb1 = 0.2\n",
    "#         if self.regularize == False:\n",
    "#             lmb1 = 0\n",
    "#         lmb2 = 0\n",
    "        \n",
    "#         if self.regularize == 'rigde':\n",
    "#             lmb2 = 0\n",
    "#         if self.regularize == 'lasso':\n",
    "#             lmb2 = 1\n",
    "#         if self.regularize == 'elastic-net':\n",
    "#             lmb2 = 0.4\n",
    "#         print('lambda 1 est ',lmb1)\n",
    "#         print('lambda 2 est ',lmb2)\n",
    "        \n",
    "        \n",
    "#         costFct = 0\n",
    "#         costFctEvol = []\n",
    "#         count = 0\n",
    "#         while self.testRegCostFct(predictions, label, lmb1, lmb2, parameters, costFct, self.epsilon):\n",
    "#             count += 1\n",
    "#             costFct = self.regCostFunction(predictions, label, lmb1, lmb2, parameters)\n",
    "#             grads = self.regGradients(predictions, label, features, lmb1, lmb2, parameters)\n",
    "#             parameters = self.updateParameters(parameters, grads, self.alpha)\n",
    "#             predictions = self.hypothesis(features, parameters)\n",
    "#             costFctEvol.append(costFct)\n",
    "            \n",
    "#         plt.xlabel('Iterations')\n",
    "#         plt.ylabel('Fonction cout')\n",
    "#         plt.title('Evolution de la fonction cout en fonctions des iterations')\n",
    "#         plt.plot(costFctEvol)\n",
    "#         return parameters\n",
    "    \n",
    "#     def _add_bias(self, features):\n",
    "#         \"\"\"Add bias column (1 vector)\n",
    "#         \"\"\"\n",
    "#         bias = np.ones(features.shape[0])\n",
    "#         return np.column_stack([features, bias])\n",
    "        \n",
    "#     def hypothesis(self, x, theta):\n",
    "#         \"\"\"Compute our hypothesis model (linear regression), use a fonction:\n",
    "#         \"\"\"\n",
    "#         return np.dot(x, theta)\n",
    "    \n",
    "#     def costFunction(self, yhat, y):\n",
    "#         \"\"\"Fonction de coût\n",
    "#         \"\"\"\n",
    "#         return np.square(yhat - y).sum() / (2*y.shape[0])\n",
    "    \n",
    "#     def regCostFunction(self, yhat, y, lmb1, lmb2, theta):\n",
    "#         \"\"\"Fonction de coût régularisée\n",
    "#         \"\"\"\n",
    "#         #return self.costFunction(yhat, y) + lmb1/((2*y.shape[0]) * np.square(theta)).sum()\n",
    "\n",
    "\n",
    "#         return self.costFunction(yhat, y) + lmb1*(((1-lmb2)/2) * np.square(theta).sum() + lmb2*(np.abs(theta)).sum())\n",
    "    \n",
    "#     def gradients(self, yhat, y, x):\n",
    "#         \"\"\"Dérivée de la fonction de coût == gradients\n",
    "#         \"\"\"\n",
    "        \n",
    "#         return (((yhat - y) * x).sum(axis=0) / x.shape[0]).reshape(x.shape[1],1)\n",
    "\n",
    "#     def regGradients(self, yhat, y, x, lmb1 ,lmb2 , theta):\n",
    "#         \"\"\"Dérivée de la fonction de coût regularisée\n",
    "#         \"\"\"\n",
    "#         #return (((yhat - y) * x).sum(axis=0) / x.shape[0]).reshape(x.shape[1],1) + lmb1/x.shape[0]*theta\n",
    "\n",
    "#         return (((yhat - y) * x).sum(axis=0) / x.shape[0]).reshape(x.shape[1],1) + (lmb1*(1-lmb2))/x.shape[0]*theta\n",
    "    \n",
    "#     def updateParameters(self, parameters, grads, alpha):\n",
    "#         \"\"\"Gradient descent: mise à jour des paramètres\n",
    "#         \"\"\"\n",
    "#         return parameters - alpha * grads\n",
    "    \n",
    "#     def testRegCostFct(self, yhat, y, lmb1, lmb2, theta, prevCostFct, epsilon):\n",
    "#         \"\"\" Fonction pour tester l'évolution de la fonction de coût régularisée\n",
    "            \n",
    "#             Returns\n",
    "#             -------\n",
    "#             test : bool\n",
    "#                 vrai = continuer la descente de gradient\n",
    "#         \"\"\"\n",
    "#         return np.abs(self.regCostFunction(yhat, y, lmb1, lmb2, theta) - prevCostFct) >= epsilon*prevCostFct\n",
    "    \n",
    "#     def train_test_split(self, X, y, ratio=0.3, random_seed = 42):\n",
    "#         \"\"\" Fonction pour subdiviser les donnees en donnees d'entrainement et donnees de test.\n",
    "        \n",
    "#              Parametres\n",
    "#             ----------\n",
    "#             X : 2d sequence of float\n",
    "#                 The input parameters.\n",
    "#             y : 2d sequence of float\n",
    "#                 The output parameters\n",
    "#             ratio : La ratio du test set.\n",
    "            \n",
    "#             Returns\n",
    "#             -------\n",
    "#             X_train : les features d'entrainement.\n",
    "#             y_train : les labels d'entrainement.\n",
    "#             X_test : les features de test.\n",
    "#             y_test : les labels de test.\n",
    "            \n",
    "#         \"\"\"\n",
    "#         X_train = []\n",
    "#         y_train = []\n",
    "#         X_test = []\n",
    "#         y_test = []\n",
    "#         rows = len(X)\n",
    "#         random.seed(random_seed)\n",
    "#         test_index = random.sample(range(0,rows), int(rows*ratio))\n",
    "#         for i in range(rows):\n",
    "#             if i in test_index:\n",
    "#                 X_test.append(X[i])\n",
    "#                 y_test.append(y[i])\n",
    "#             else:\n",
    "#                 X_train.append(X[i])\n",
    "#                 y_train.append(y[i])\n",
    "#         return np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "    \n",
    "#     def mae(self, y, y_pred) :\n",
    "#         return np.abs(y_pred - y).sum() / (2*y.shape[0])\n",
    "    \n",
    "#     def rmse(self, y, y_pred) :\n",
    "#         return np.sqrt(np.square(y_pred - y).sum() / (2*y.shape[0]))\n",
    "    \n",
    "#     def r2_score(self, y, y_pred) :\n",
    "#         return 1 - (np.square(y_pred - y).sum() / np.square(y_pred - np.mean(y)).sum())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "616a19c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradient_descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e955661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradient_descent import GradientDescent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "733fc9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = GradientDescent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06476cd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-90efdaf96f25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'best' is not defined"
     ]
    }
   ],
   "source": [
    "best[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17630df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = GradientDescent(regularize = 'ridge',learning_rate = 0.03, normalize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae1d966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "np.random.seed(67)\n",
    "X = 3 * np.random.rand(100, 1) - 2\n",
    "Y = 2*X + 7 + np.random.randn(100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237211bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d264cf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import load_diabetes\n",
    "# diabetes = load_diabetes()\n",
    "# X = diabetes.data\n",
    "# Y = diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22daa386",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e37d3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 > 9e100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac7d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc39cc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.reshape(-1,1)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82337f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.std(X, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e976b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = g.train_test_split(X,Y,ratio=0.3,random_seed=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca02ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bffaf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f15c2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.scatter(X_train,y_train,alpha = 0.7)\n",
    "# plt.xlabel('Features')\n",
    "# plt.ylabel('Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ddb24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f24460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = g.tunning(X_train, y_train, \"mae\", nb_params=10, validation_ratio = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9e8592",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxi = 0\n",
    "best = 0\n",
    "for i in lambd:\n",
    "    g.fit(X_train,y_train, lambd = i)\n",
    "    y_pred = g.predict(X_test)\n",
    "    score = g.rmse(y_pred, y_test)\n",
    "    if score > maxi:\n",
    "        maxi = score\n",
    "    best = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90282a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb1a361",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6309b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope , intercept = g.parameters_[0][0],  g.parameters_[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a038c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.parameters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7c4baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be3fe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.scatter(X,Y,alpha = 0.7)\n",
    "# plt.plot(X,X*slope+intercept, color = 'red')\n",
    "# plt.xlabel('Features')\n",
    "# plt.ylabel('Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60e7b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = g.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134e8ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.r2_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ebab82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73876da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
